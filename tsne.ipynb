{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m/home/s2435462/HRC/code/tsne_silhouette.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meinops\u001b[39;00m \u001b[39mimport\u001b[39;00m rearrange, repeat\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py:233\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=218'>219</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=219'>220</a>\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=220'>221</a>\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=228'>229</a>\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=229'>230</a>\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=230'>231</a>\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n",
      "\u001b[0;32m--> <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=232'>233</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=233'>234</a>\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;32m    <a href='file:///home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/torch/__init__.py?line=234'>235</a>\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from trajectory import Trajectory, extract_fixed_sized_segments, split_into_train_and_test, remove_short_trajectories, get_categories, get_UTK_categories\n",
    "# from transformer_store_attn import TubeletTemporalSpatialPart_concat_chan_2_Transformer_store_attn, TubeletTemporalPart_concat_chan_1_Transformer_store_attn, TubeletTemporalTransformer_store_attn, TubeletTemporalPart_mean_chan_1_Transformer_store_attn, TubeletTemporalPart_mean_chan_2_Transformer_store_attn, TubeletTemporalPart_concat_chan_2_Transformer_store_attn, TemporalTransformer_4_store_attn, TemporalTransformer_3_store_attn, TemporalTransformer_2_store_attn, BodyPartTransformer_store_attn, SpatialTemporalTransformer_store_attn, TemporalTransformer_store_attn\n",
    "from trajectory import TrajectoryDataset, Trajectory, extract_fixed_sized_segments, split_into_train_and_test, remove_short_trajectories, get_NTU_categories, get_categories\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "from utils import print_statistics, SetupLogger, evaluate_all, evaluate_category, conv_to_float, SetupFolders, train_acc, SetupVisFolders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ttspcc2'\n",
    "filename = 'HRC_ttspcc2_233'\n",
    "embed_dim = 32\n",
    "test_sample = 1\n",
    "test_index = 1\n",
    "segment_length = 24\n",
    "dataset = 'HRC'\n",
    "vis_type = 1\n",
    "kernel = '2,3,3'\n",
    "stride = kernel\n",
    "dec = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_body_parts(num_joints, x):\n",
    "    if num_joints == 25:\n",
    "        dim = int(x.size(2)/25)\n",
    "        x_torso_1 = x[:, :, 0:5*dim]\n",
    "        x_torso_2 = x[:, :, 8*dim:9*dim]\n",
    "        x_torso_3 = x[:, :, 12*dim:13*dim]\n",
    "        x_torso_4 = x[:, :, 16*dim:17*dim]\n",
    "        x_torso_5 = x[:, :, 20*dim:21*dim]\n",
    "        x_torso = torch.cat((x_torso_1, x_torso_2, x_torso_3, x_torso_4, x_torso_5), dim=2)\n",
    "\n",
    "        x_wrist_1 = x[:, :, 6*dim:7*dim]\n",
    "        x_wrist_2 = x[:, :, 7*dim:8*dim]\n",
    "        x_wrist_3 = x[:, :, 10*dim:11*dim]\n",
    "        x_wrist_4 = x[:, :, 11*dim:12*dim]\n",
    "        x_wrist_5 = x[:, :, 21*dim:22*dim]\n",
    "        x_wrist_6 = x[:, :, 22*dim:23*dim]\n",
    "        x_wrist_7 = x[:, :, 23*dim:24*dim]\n",
    "        x_wrist_8 = x[:, :, 24*dim:25*dim]\n",
    "        x_wrist = torch.cat((x_wrist_1, x_wrist_2, x_wrist_3, x_wrist_4, x_wrist_5, x_wrist_6, x_wrist_7, x_wrist_8), dim=2)\n",
    "\n",
    "        x_elbow_1 = x[:, :, 9*dim:10*dim]\n",
    "        x_elbow_2 = x[:, :, 5*dim:6*dim]\n",
    "        x_elbow = torch.cat((x_elbow_1, x_elbow_2), dim=2)\n",
    "\n",
    "        x_knee_1 = x[:, :, 17*dim:18*dim]\n",
    "        x_knee_2 = x[:, :, 13*dim:14*dim]\n",
    "        x_knee = torch.cat((x_knee_1, x_knee_2), dim=2)\n",
    "\n",
    "        x_ankle_1 = x[:, :, 18*dim:19*dim]\n",
    "        x_ankle_2 = x[:, :, 19*dim:20*dim]\n",
    "        x_ankle_3 = x[:, :, 14*dim:15*dim]\n",
    "        x_ankle_4 = x[:, :, 15*dim:16*dim]\n",
    "        x_ankle = torch.cat((x_ankle_1, x_ankle_2, x_ankle_3, x_ankle_4), dim=2)\n",
    "\n",
    "        x_torso_x = x_torso[:, :, ::2]\n",
    "        x_elbow_x = x_elbow[:, :, ::2]\n",
    "        x_wrist_x = x_wrist[:, :, ::2]\n",
    "        x_knee_x = x_knee[:, :, ::2]\n",
    "        x_ankle_x = x_ankle[:, :, ::2]\n",
    "\n",
    "        x_torso_y = x_torso[:, :, 1::2]\n",
    "        x_elbow_y = x_elbow[:, :, 1::2]\n",
    "        x_wrist_y = x_wrist[:, :, 1::2]\n",
    "        x_knee_y = x_knee[:, :, 1::2]\n",
    "        x_ankle_y = x_ankle[:, :, 1::2]\n",
    "\n",
    "        x_torso_x = torch.mean(torch.Tensor.float(x_torso_x), dim=2)\n",
    "        x_elbow_x = torch.mean(torch.Tensor.float(x_elbow_x), dim=2)\n",
    "        x_wrist_x = torch.mean(torch.Tensor.float(x_wrist_x), dim=2)\n",
    "        x_knee_x = torch.mean(torch.Tensor.float(x_knee_x), dim=2)\n",
    "        x_ankle_x = torch.mean(torch.Tensor.float(x_ankle_x), dim=2)\n",
    "\n",
    "        x_torso_y = torch.mean(torch.Tensor.float(x_torso_y), dim=2)\n",
    "        x_elbow_y = torch.mean(torch.Tensor.float(x_elbow_y), dim=2)\n",
    "        x_wrist_y = torch.mean(torch.Tensor.float(x_wrist_y), dim=2)\n",
    "        x_knee_y = torch.mean(torch.Tensor.float(x_knee_y), dim=2)\n",
    "        x_ankle_y = torch.mean(torch.Tensor.float(x_ankle_y), dim=2)\n",
    "\n",
    "        x_torso_x = torch.unsqueeze(x_torso_x, 2)\n",
    "        x_elbow_x = torch.unsqueeze(x_elbow_x, 2)\n",
    "        x_wrist_x = torch.unsqueeze(x_wrist_x, 2)\n",
    "        x_knee_x = torch.unsqueeze(x_knee_x, 2)\n",
    "        x_ankle_x = torch.unsqueeze(x_ankle_x, 2)\n",
    "\n",
    "        x_torso_y = torch.unsqueeze(x_torso_y, 2)\n",
    "        x_elbow_y = torch.unsqueeze(x_elbow_y, 2)\n",
    "        x_wrist_y = torch.unsqueeze(x_wrist_y, 2)\n",
    "        x_knee_y = torch.unsqueeze(x_knee_y, 2)\n",
    "        x_ankle_y = torch.unsqueeze(x_ankle_y, 2)\n",
    "\n",
    "        x_torso = torch.cat((x_torso_x, x_torso_y), dim=2)\n",
    "        x_elbow = torch.cat((x_elbow_x, x_elbow_y), dim=2)\n",
    "        x_wrist = torch.cat((x_wrist_x, x_wrist_y), dim=2)\n",
    "        x_knee = torch.cat((x_knee_x, x_knee_y), dim=2)\n",
    "        x_ankle = torch.cat((x_ankle_x, x_ankle_y), dim=2)\n",
    "\n",
    "        x = torch.cat((x_torso, x_elbow, x_wrist, x_knee, x_ankle), dim=2)\n",
    "        return x\n",
    "\n",
    "\n",
    "    elif num_joints == 17:\n",
    "        #x_torso = x[:, :, 0:9*2]\n",
    "        x_torso_1 = x[:, :, 0:7*2] #joints 0,1,2,3,4,5,6 (head and shoulders) \n",
    "        x_torso_2 = x[:, :, 11*2:13*2] #joints 11,12 (hips)\n",
    "        #print('x_torso_1[0]', x_torso_1[0])\n",
    "        #print('x_torso_2[0]', x_torso_2[0])\n",
    "        x_torso = torch.cat((x_torso_1, x_torso_2), dim=2)\n",
    "        #print('x_torso[0]', x_torso[0])\n",
    "        \n",
    "        x_elbow = x[:, :, 7*2:9*2]\n",
    "        x_wrist = x[:, :, 9*2:11*2]\n",
    "        x_knee = x[:, :, 13*2:15*2]\n",
    "        x_ankle = x[:, :, 15*2:17*2]\n",
    "\n",
    "        '''\n",
    "        print('x_torso shape', x_torso.shape)\n",
    "        print('x_elbow shape', x_elbow.shape)\n",
    "        print('x_wrist shape', x_wrist.shape)\n",
    "        print('x_knee shape', x_knee.shape)\n",
    "        print('x_ankle shape', x_ankle.shape)\n",
    "        '''\n",
    "\n",
    "        x_torso_x = x_torso[:, :, ::2]\n",
    "        x_elbow_x = x_elbow[:, :, ::2]\n",
    "        x_wrist_x = x_wrist[:, :, ::2]\n",
    "        x_knee_x = x_knee[:, :, ::2]\n",
    "        x_ankle_x = x_ankle[:, :, ::2]\n",
    "\n",
    "        '''\n",
    "        print('\\nx_torso_x shape', x_torso_x.shape)\n",
    "        print('x_elbow_x shape', x_elbow_x.shape)\n",
    "        print('x_wrist_x shape', x_wrist_x.shape)\n",
    "        print('x_knee_x shape', x_knee_x.shape)\n",
    "        print('x_ankle_x shape', x_ankle_x.shape)\n",
    "        '''\n",
    "\n",
    "        x_torso_y = x_torso[:, :, 1::2]\n",
    "        x_elbow_y = x_elbow[:, :, 1::2]\n",
    "        x_wrist_y = x_wrist[:, :, 1::2]\n",
    "        x_knee_y = x_knee[:, :, 1::2]\n",
    "        x_ankle_y = x_ankle[:, :, 1::2]\n",
    "\n",
    "        #print('\\nx_torso_x', x_torso_x)\n",
    "        #print('x_torso_y', x_torso_y)\n",
    "\n",
    "        x_torso_x = torch.mean(torch.Tensor.float(x_torso_x), dim=2)\n",
    "        x_elbow_x = torch.mean(torch.Tensor.float(x_elbow_x), dim=2)\n",
    "        x_wrist_x = torch.mean(torch.Tensor.float(x_wrist_x), dim=2)\n",
    "        x_knee_x = torch.mean(torch.Tensor.float(x_knee_x), dim=2)\n",
    "        x_ankle_x = torch.mean(torch.Tensor.float(x_ankle_x), dim=2)\n",
    "\n",
    "        x_torso_y = torch.mean(torch.Tensor.float(x_torso_y), dim=2)\n",
    "        x_elbow_y = torch.mean(torch.Tensor.float(x_elbow_y), dim=2)\n",
    "        x_wrist_y = torch.mean(torch.Tensor.float(x_wrist_y), dim=2)\n",
    "        x_knee_y = torch.mean(torch.Tensor.float(x_knee_y), dim=2)\n",
    "        x_ankle_y = torch.mean(torch.Tensor.float(x_ankle_y), dim=2)\n",
    "\n",
    "        x_torso_x = torch.unsqueeze(x_torso_x, 2)\n",
    "        x_elbow_x = torch.unsqueeze(x_elbow_x, 2)\n",
    "        x_wrist_x = torch.unsqueeze(x_wrist_x, 2)\n",
    "        x_knee_x = torch.unsqueeze(x_knee_x, 2)\n",
    "        x_ankle_x = torch.unsqueeze(x_ankle_x, 2)\n",
    "\n",
    "        x_torso_y = torch.unsqueeze(x_torso_y, 2)\n",
    "        x_elbow_y = torch.unsqueeze(x_elbow_y, 2)\n",
    "        x_wrist_y = torch.unsqueeze(x_wrist_y, 2)\n",
    "        x_knee_y = torch.unsqueeze(x_knee_y, 2)\n",
    "        x_ankle_y = torch.unsqueeze(x_ankle_y, 2)\n",
    "\n",
    "        '''\n",
    "        print('\\nx_torso_x shape', x_torso_x.shape)\n",
    "        print('x_elbow_x shape', x_elbow_x.shape)\n",
    "        print('x_wrist_x shape', x_wrist_x.shape)\n",
    "        print('x_knee_x shape', x_knee_x.shape)\n",
    "        print('x_ankle_x shape', x_ankle_x.shape)\n",
    "\n",
    "        print('\\nx_torso_x', x_torso_x)\n",
    "        print('x_torso_y', x_torso_y)\n",
    "        '''\n",
    "\n",
    "\n",
    "        x_torso = torch.cat((x_torso_x, x_torso_y), dim=2)\n",
    "        x_elbow = torch.cat((x_elbow_x, x_elbow_y), dim=2)\n",
    "        x_wrist = torch.cat((x_wrist_x, x_wrist_y), dim=2)\n",
    "        x_knee = torch.cat((x_knee_x, x_knee_y), dim=2)\n",
    "        x_ankle = torch.cat((x_ankle_x, x_ankle_y), dim=2)\n",
    "\n",
    "        '''\n",
    "        print('\\nx_torso shape', x_torso.shape)\n",
    "        print('x_elbow shape', x_elbow.shape)\n",
    "        print('x_wrist shape', x_wrist.shape)\n",
    "        print('x_knee shape', x_knee.shape)\n",
    "        print('x_ankle shape', x_ankle.shape)\n",
    "\n",
    "        print('\\nx_torso', x_torso)\n",
    "        print('\\nx_ankle', x_ankle)\n",
    "        '''\n",
    "\n",
    "        x = torch.cat((x_torso, x_elbow, x_wrist, x_knee, x_ankle), dim=2)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_keypoint(skeleton, position, dim):\n",
    "    # device = torch.device('cuda')# if torch.cuda.is_available() else 'cpu')\n",
    "    # part = torch.empty(0)\n",
    "    # part.to(device)\n",
    "    # part = None\n",
    "    for joint in position:\n",
    "        x = skeleton[:, :, (joint-1)*dim : joint*dim]\n",
    "        # print(x.device)\n",
    "        # print(part.device)\n",
    "        try:\n",
    "            part = torch.cat((part, x), dim=2)\n",
    "        except:\n",
    "            part = x\n",
    "        # if position.index(x) == 0:\n",
    "        #     part = x\n",
    "        # else:\n",
    "        #     part = torch.cat((part, x), dim=2)\n",
    "    return part\n",
    "#Transformer model\n",
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        \n",
    "        # NOTE scale factor can be manually set to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 dropout=0., act_layer=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        #self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout) #first try a simple dropout instead of drop path\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        #x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        x = x + self.dropout(self.attn(self.norm1(x)))\n",
    "        x = x + self.dropout(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class TubeletTemporalSpatialPart_concat_chan_2_Transformer(nn.Module):\n",
    "    def __init__(self, dataset=None, num_classes=13, num_frames=12, num_joints=17, in_chans=2, embed_dim_ratio=64, kernel=None, stride=None, depth=4,\n",
    "                 num_heads=8, mlp_ratio=2., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., dropout=0.2, pad_mode='constant'):\n",
    "        \"\"\"    ##########hybrid_backbone=None, representation_size=None,\n",
    "        Args:\n",
    "            num_classes (int): number of classes for classification head, HR-Crime constists of 13 crime categories\n",
    "            num_frames (int): number of input frames\n",
    "            num_joints (int): number of joints per skeleton\n",
    "            in_chans (int): number of input channels, 2D joints have 2 channels: (x,y)\n",
    "            embed_dim_ratio (int): embedding dimension ratio\n",
    "            depth (int): depth of transformer\n",
    "            num_heads (int): number of attention heads\n",
    "            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n",
    "            qkv_bias (bool): enable bias for qkv if True\n",
    "            qk_scale (float): override default qk scale of head_dim ** -0.5 if set\n",
    "            drop_rate (float): dropout rate\n",
    "            attn_drop_rate (float): attention dropout rate\n",
    "            drop_path_rate (float): stochastic depth rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dataset = dataset\n",
    "        self.pad_mode = pad_mode\n",
    "        self.num_embed = (int((num_frames-kernel[0])/stride[0]) + 1) * (int((3-kernel[1])/stride[1]) + 1) * (int((3-kernel[2])/stride[2]) + 1)\n",
    "        \n",
    "        embed_dim = embed_dim_ratio * self.num_embed #* 5   #### temporal embed_dim is embed_dim_ratio x num_embed (op of 3dconv) x 5 (no. of body parts)\n",
    "\n",
    "        ### Tubelet Embedder\n",
    "        if \"NTU\" in dataset or \"HRC\" in dataset:\n",
    "            self.torso_conv = torch.nn.Conv3d(in_chans, embed_dim_ratio, kernel_size=kernel, stride=stride)\n",
    "            self.elbows_conv = torch.nn.Conv3d(in_chans, embed_dim_ratio, kernel_size=kernel, stride=stride)\n",
    "            self.wrists_conv = torch.nn.Conv3d(in_chans, embed_dim_ratio, kernel_size=kernel, stride=stride)\n",
    "            self.knees_conv = torch.nn.Conv3d(in_chans, embed_dim_ratio, kernel_size=kernel, stride=stride)\n",
    "            self.ankles_conv = torch.nn.Conv3d(in_chans, embed_dim_ratio, kernel_size=kernel, stride=stride)\n",
    "\n",
    "        ### Tubelet Embedder - Position embedding\n",
    "        if self.dataset == \"HRC\":\n",
    "            self.Torso_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #9 joints\n",
    "            self.Elbow_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts\n",
    "            self.Wrist_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts\n",
    "            self.Knee_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts\n",
    "            self.Ankle_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts\n",
    "        elif \"NTU\" in self.dataset:\n",
    "            if \"2D\" in self.dataset:\n",
    "                self.Torso_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #9 joints\n",
    "                self.Elbow_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts \n",
    "                self.Wrist_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts \n",
    "                self.Knee_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts \n",
    "                self.Ankle_pos_embed = nn.Parameter(torch.zeros(self.num_embed, embed_dim_ratio)) #2 joints in remaining body parts \n",
    "\n",
    "\n",
    "        self.Temporal_pos_embed = nn.Parameter(torch.zeros(5 + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        '''\n",
    "        self.Spatial_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "        '''\n",
    "\n",
    "        # Spatial\n",
    "        \n",
    "        self.Torso_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "        \n",
    "        self.Elbow_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "        \n",
    "        self.Wrist_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        self.Knee_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        self.Ankle_blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim_ratio, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "        \n",
    "        # Temporal\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, dropout=dropout)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        #self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.Spatial_norm =  nn.LayerNorm(embed_dim_ratio, eps=1e-6)\n",
    "        self.Temporal_norm =  nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "\n",
    "        print('num_classes',num_classes)\n",
    "        print('embed_dim', embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, embed_dim))\n",
    "        \n",
    "\n",
    "        # Classifier head(s)\n",
    "        \"Define standard linear to map the final output sequence to class logits\"\n",
    "        self.head = nn.Linear(embed_dim, num_classes) #do not use softmax here. nn.CrossEntropyLoss takes the logits as input and calculates the softmax\n",
    "        \n",
    "        #print('self.head',self.head)\n",
    "        #print('num_classes',num_classes)\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "        # taken from https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "    #   self.Spatial_patch_to_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.torso_conv.weight.data.uniform_(-initrange, initrange)\n",
    "        self.elbows_conv.weight.data.uniform_(-initrange, initrange)\n",
    "        self.wrists_conv.weight.data.uniform_(-initrange, initrange)\n",
    "        self.knees_conv.weight.data.uniform_(-initrange, initrange)\n",
    "        self.ankles_conv.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.head.bias.data.zero_()\n",
    "        self.head.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def Torso_forward_features(self, x):\n",
    "        x = self.torso_conv(x)\n",
    "        x = rearrange(x, \"b e n1 n2 n3 -> b (n1 n2 n3) e\")\n",
    "        x = self.pos_drop(x + self.Torso_pos_embed)\n",
    "\n",
    "        for blk in self.Torso_blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.Spatial_norm(x)\n",
    "        x = rearrange(x, \"b n e -> b (n e)\")\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def Elbow_forward_features(self, x):\n",
    "        x = self.elbows_conv(x)\n",
    "        x = rearrange(x, \"b e n1 n2 n3 -> b (n1 n2 n3) e\")\n",
    "        x = self.pos_drop(x + self.Elbow_pos_embed)\n",
    "\n",
    "        for blk in self.Elbow_blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.Spatial_norm(x)\n",
    "        x = rearrange(x, \"b n e -> b (n e)\")\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def Wrist_forward_features(self, x):\n",
    "        x = self.wrists_conv(x)\n",
    "        x = rearrange(x, \"b e n1 n2 n3 -> b (n1 n2 n3) e\")\n",
    "        x = self.pos_drop(x + self.Wrist_pos_embed)\n",
    "\n",
    "        for blk in self.Wrist_blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.Spatial_norm(x)\n",
    "        x = rearrange(x, \"b n e -> b (n e)\")\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def Knee_forward_features(self, x):\n",
    "        x = self.knees_conv(x)\n",
    "        x = rearrange(x, \"b e n1 n2 n3 -> b (n1 n2 n3) e\")\n",
    "        x = self.pos_drop(x + self.Knee_pos_embed)\n",
    "\n",
    "        for blk in self.Knee_blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.Spatial_norm(x)\n",
    "        x = rearrange(x, \"b n e -> b (n e)\")\n",
    "\n",
    "        return x\n",
    "\n",
    "    def Ankle_forward_features(self, x):\n",
    "        x = self.ankles_conv(x)\n",
    "        x = rearrange(x, \"b e n1 n2 n3 -> b (n1 n2 n3) e\")\n",
    "        x = self.pos_drop(x + self.Ankle_pos_embed)\n",
    "\n",
    "        for blk in self.Ankle_blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.Spatial_norm(x)\n",
    "        x = rearrange(x, \"b n e -> b (n e)\")\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "\n",
    "        x = self.pos_drop(x + self.Temporal_pos_embed)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.Temporal_norm(x)\n",
    "        cls_token_final = x[:, 0]\n",
    "        return cls_token_final\n",
    "\n",
    "\n",
    "    def tubelet_embedding(self, x):\n",
    "        if self.dataset == \"NTU_3D\":\n",
    "            torso = get_keypoint(x, [], 3)\n",
    "        elif self.dataset == \"NTU_2D\":\n",
    "            torso = get_keypoint(x, [4, 3, 9, 21, 5, 2, 17, 1, 13], 2)\n",
    "            elbows = get_keypoint(x, [10, 6], 2)\n",
    "            wrists = get_keypoint(x, [11, 12, 24, 25, 7, 8, 22, 23], 2)\n",
    "            knees = get_keypoint(x, [18, 14], 2)\n",
    "            ankles = get_keypoint(x, [19, 20, 15, 16], 2)\n",
    "\n",
    "            torso = rearrange(torso, \"b f (x y c) -> b c f x y\", x= 3, y =3)       ## shape: b 2 f 3 3\n",
    "            # torso = F.pad(input=torso, pad=(0, 0, 2, 1), mode='constant', value=0)   ## Shape: b f 6 6 \n",
    "            # torso = torso.unsqueeze(1)                                         ## Shape: b 1 f 6 6\n",
    "\n",
    "            elbows = rearrange(elbows, \"b f (x y c) -> b c f x y\", x= 1, y =2)     ## Shape: b f 1 2 \n",
    "            if self.pad_mode == 'constant':\n",
    "                elbows = F.pad(input=elbows, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 2 2\n",
    "            else:\n",
    "                elbows = F.pad(input=elbows, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 2 2\n",
    "            # elbows = elbows.unsqueeze(1)\n",
    "\n",
    "            wrists = F.pad(wrists ,(0,2)) # Extend wrists by one keypoint so that we can transform it into 3x3 \n",
    "            wrists = rearrange(wrists, \"b f (x y c) -> b c f x y\", x= 3, y =3)     ## Shape: b f 3 3\n",
    "            # wrists = F.pad(input=wrists, pad=(0, 0, 1, 1), mode='constant', value=0) ## Shape: b f 4 4\n",
    "            # wrists = wrists.unsqueeze(1)                                       ## Shape: b 1 f 6 6\n",
    "\n",
    "            knees = rearrange(knees, \"b f (x y c) -> b c f x y\", x= 1, y =2)       ## Shape: b f 1 2\n",
    "            if self.pad_mode == 'constant':\n",
    "                knees = F.pad(input=knees, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 2 2\n",
    "            else:\n",
    "                knees = F.pad(input=knees, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 2 2\n",
    "            # knees = knees.unsqueeze(1)                                         ## Shape: b 1 f 6 6\n",
    "\n",
    "            ankles = rearrange(ankles, \"b f (x y c) -> b c f x y\", x= 2, y =2)     ## Shape: b f 2 2\n",
    "            if self.pad_mode == 'constant':\n",
    "                ankles = F.pad(input=ankles, pad=(1, 0, 1, 0), mode='constant', value=0) ## Shape: b f 6 6\n",
    "            else:\n",
    "                ankles = F.pad(input=ankles, pad=(1, 0, 1, 0, 0, 0), mode=self.pad_mode) ## Shape: b f 6 6\n",
    "            # ankles = ankles.unsqueeze(1)                                       ## Shape: b 1 f 6 6\n",
    "\n",
    "        elif self.dataset == \"HRC\":\n",
    "            torso = get_keypoint(x, [1, 2, 3, 4, 5, 6, 7, 12, 13], 2)\n",
    "            elbows = get_keypoint(x, [8, 9], 2)\n",
    "            wrists = get_keypoint(x, [10, 11], 2)\n",
    "            knees = get_keypoint(x, [14, 15], 2)\n",
    "            ankles = get_keypoint(x, [16, 17], 2)\n",
    "\n",
    "            torso = rearrange(torso, \"b f (x y c) -> b c f x y\", x= 3, y =3)       ## shape: b 2 f 3 3\n",
    "            # torso = F.pad(input=torso, pad=(0, 0, 2, 1), mode='constant', value=0)   ## Shape: b f 6 6 \n",
    "            # torso = torso.unsqueeze(1)                                         ## Shape: b 1 f 6 6\n",
    "\n",
    "            elbows = rearrange(elbows, \"b f (x y c) -> b c f x y\", x= 1, y =2)     ## Shape: b 2 f 1 2 \n",
    "            if self.pad_mode == 'constant':\n",
    "                elbows = F.pad(input=elbows, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 6 6\n",
    "            else:\n",
    "                elbows = F.pad(input=elbows, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 6 6\n",
    "            # elbows = elbows.unsqueeze(1)\n",
    "\n",
    "            wrists = rearrange(wrists, \"b f (x y c) -> b c f x y\", x= 1, y =2)     ## Shape: b 2 f 1 2\n",
    "            if self.pad_mode == 'constant':\n",
    "                wrists = F.pad(input=wrists, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 6 6\n",
    "            else:\n",
    "                wrists = F.pad(input=wrists, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 6 6\n",
    "            # wrists = wrists.unsqueeze(1)                                       ## Shape: b 1 f 6 6\n",
    "\n",
    "            knees = rearrange(knees, \"b f (x y c) -> b c f x y\", x= 1, y =2)       ## Shape: b 2 f 1 2\n",
    "            if self.pad_mode == 'constant':\n",
    "                knees = F.pad(input=knees, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 6 6\n",
    "            else:\n",
    "                knees = F.pad(input=knees, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 6 6\n",
    "            # knees = knees.unsqueeze(1)                                         ## Shape: b 1 f 6 6\n",
    "\n",
    "            ankles = rearrange(ankles, \"b f (x y c) -> b c f x y\", x= 1, y =2)     ## Shape: b 2 f 1 2\n",
    "            if self.pad_mode == 'constant':\n",
    "                ankles = F.pad(input=ankles, pad=(1, 0, 1, 1), mode='constant', value=0) ## Shape: b f 6 6\n",
    "            else:\n",
    "                ankles = F.pad(input=ankles, pad=(1, 0, 1, 1, 0, 0), mode=self.pad_mode) ## Shape: b f 6 6\n",
    "            # ankles = ankles.unsqueeze(1)                                       ## Shape: b 1 f 6 6\n",
    "\n",
    "        torso_embed = self.Torso_forward_features(torso)\n",
    "        elbows_embed = self.Elbow_forward_features(elbows)\n",
    "        wrists_embed = self.Wrist_forward_features(wrists)\n",
    "        knees_embed = self.Knee_forward_features(knees)\n",
    "        ankles_embed = self.Ankle_forward_features(ankles)\n",
    "\n",
    "        x = torch.stack((torso_embed, elbows_embed, wrists_embed, knees_embed, ankles_embed), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tubelet_embedding(x)\n",
    "     \n",
    "        x = self.forward_features(x)\n",
    "        \n",
    "        # x = self.head(x)\n",
    "        # x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"HRC\":\n",
    "    num_classes = 13\n",
    "    num_joints = 17\n",
    "    num_parts = 5\n",
    "    in_chans = 2\n",
    "elif dataset == \"UTK\":\n",
    "    num_classes = 10\n",
    "    num_joints = 20\n",
    "    in_chans = 3\n",
    "elif \"NTU\" in dataset:\n",
    "    if \"2D\" in dataset:\n",
    "        num_classes = 120\n",
    "        num_joints = 25\n",
    "        num_parts = 5\n",
    "        in_chans = 2\n",
    "    elif \"3D\" in dataset:\n",
    "        num_classes = 120\n",
    "        num_joints = 25\n",
    "        num_parts = 5\n",
    "        in_chans = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\model state dict /home/s2435462/HRC/results/tsne_silhouette/HRC_ttspcc2_233state_dict.pt already exists\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.join('/home/s2435462/HRC/results/', dataset, filename, 'models', filename+'_fold_1.pt')\n",
    "# PATH = '/home/s2435462/HRC/results/'+dataset+'/NTU_2D_ttpcc1/models'\n",
    "# PATH = '/data/s3447707/MasterThesis/trained_models/' + filename + '.pt'\n",
    "model_ = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "NEW_PATH = '/home/s2435462/HRC/results/tsne_silhouette' +'/'+ filename + 'state_dict.pt'\n",
    "if not os.path.isfile(NEW_PATH):\n",
    "    torch.save(model_.state_dict(), NEW_PATH)\n",
    "    print('\\nsave model state dict to', NEW_PATH)\n",
    "else:\n",
    "    print('\\model state dict %s already exists' % (NEW_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 13\n",
      "embed_dim 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TubeletTemporalSpatialPart_concat_chan_2_Transformer(\n",
       "  (torso_conv): Conv3d(2, 32, kernel_size=(2, 3, 3), stride=(2, 3, 3))\n",
       "  (elbows_conv): Conv3d(2, 32, kernel_size=(2, 3, 3), stride=(2, 3, 3))\n",
       "  (wrists_conv): Conv3d(2, 32, kernel_size=(2, 3, 3), stride=(2, 3, 3))\n",
       "  (knees_conv): Conv3d(2, 32, kernel_size=(2, 3, 3), stride=(2, 3, 3))\n",
       "  (ankles_conv): Conv3d(2, 32, kernel_size=(2, 3, 3), stride=(2, 3, 3))\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (Torso_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Elbow_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Wrist_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Knee_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Ankle_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=768, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=768, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=768, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=768, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Spatial_norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "  (Temporal_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=384, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model = TubeletTemporalSpatialPart_concat_chan_2_Transformer(dataset=dataset, embed_dim_ratio=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1, pad_mode = 'constant')\n",
    "\n",
    "\n",
    "#Load model state dict\n",
    "model.load_state_dict(torch.load(NEW_PATH), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg['DECOMPOSED']['ENABLE']:\n",
    "#     if cfg['DECOMPOSED']['TYPE'] == \"GR\":\n",
    "#         dec_GR_path = \"decom_GR_\"\n",
    "#     elif cfg['DECOMPOSED']['TYPE'] == \"GS\":\n",
    "#         dec_GR_path = \"decom_\"\n",
    "\n",
    "if dataset==\"HRC\":\n",
    "    decomposed = 'something' if dec else \"\"\n",
    "    dimension = \"2D\"\n",
    "\n",
    "    PIK_train = \"/home/s2435462/HRC/data/\"+dataset+\"/trajectories_train_HRC_\"+decomposed+dimension+\".dat\"\n",
    "    PIK_test = \"/home/s2435462/HRC/data/\"+dataset+\"/trajectories_test_HRC_\"+decomposed+dimension+\".dat\"\n",
    "\n",
    "    all_categories = get_categories()\n",
    "elif dataset == \"UTK\":\n",
    "    PIK_train = \"./data/train_UTK_trajectories.dat\"\n",
    "    PIK_test = \"./data/test_UTK_trajectories.dat\"\n",
    "    all_categories = get_UTK_categories()\n",
    "elif \"NTU\" in dataset:\n",
    "    dimension = dataset.split('_')[-1]\n",
    "    decomposed = 'something' if dec else \"\"\n",
    "\n",
    "    PIK_train = \"/home/s2435462/HRC/data/\"+dataset+\"/trajectories_train_NTU_\"+decomposed+dimension+\".dat\"\n",
    "    PIK_test = \"/home/s2435462/HRC/data/\"+dataset+\"/trajectories_test_NTU_\"+decomposed+dimension+\".dat\"\n",
    "    all_categories = get_NTU_categories()\n",
    "else:\n",
    "    raise Exception('dataset not recognized, must be HRC or NTU')\n",
    "\n",
    "\n",
    "with open(PIK_test, \"rb\") as f:\n",
    "    test_crime_trajectories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_segments 832696\n"
     ]
    }
   ],
   "source": [
    "def collator_for_lists(batch):\n",
    "        '''\n",
    "        Reference : https://stackoverflow.com/questions/64883998/pytorch-dataloader-shows-odd-behavior-with-string-dataset\n",
    "        Reference : https://stackoverflow.com/questions/52818145/why-pytorch-dataloader-behaves-differently-on-numpy-array-and-list\n",
    "        '''\n",
    "        # assert all('sentences' in x for x in batch)\n",
    "        # assert all('label' in x for x in batch)\n",
    "        return {\n",
    "            'id': [x['id'] for x in batch],\n",
    "            'videos': [x['videos'] for x in batch],\n",
    "            'persons': [x['persons'] for x in batch],\n",
    "            'frames': torch.tensor(np.array([x['frames'] for x in batch])),\n",
    "            'categories': torch.tensor(np.array([x['categories'] for x in batch])),\n",
    "            'coordinates': torch.tensor(np.array([x['coordinates'] for x in batch]))\n",
    "        }\n",
    "\n",
    "\n",
    "# test_sample_trajectory= {}\n",
    "\n",
    "# test_sample_trajectory[test_sample] = test_crime_trajectories[test_sample]\n",
    "\n",
    "# print(test_sample_trajectory)\n",
    "\n",
    "# print('\\nTest sample %s has %d frames' % (test_sample, len(test_sample_trajectory[test_sample].frames)))\n",
    "\n",
    "test = TrajectoryDataset(*extract_fixed_sized_segments(dataset, test_crime_trajectories, input_length=segment_length))\n",
    "\n",
    "number_of_segments = len(test)\n",
    "print('number_of_segments', number_of_segments)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size = 500, shuffle=False, collate_fn=collator_for_lists)\n",
    "\n",
    "# traj_ids_test, traj_videos_test, traj_persons_test, traj_frames_test, traj_categories_test, X_test = extract_fixed_sized_segments(dataset, test_sample_trajectory, input_length=segment_length)\n",
    "\n",
    "#Evaluate test sample\n",
    "# test_dataloader = torch.utils.data.DataLoader([ [traj_categories_test[i], traj_videos_test[i], traj_persons_test[i], traj_frames_test[i], X_test[i] ] for i in range(len(traj_ids_test))], shuffle=False, batch_size=number_of_segments) \n",
    "# labels, videos, persons, frames, categories, data = next(iter(test_dataloader)) #test_dataloader consists of only 1 batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.tensor([]).to('cpu')\n",
    "classes = torch.LongTensor([]).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for iter, batch in enumerate(test_dataloader):\n",
    "    ids, videos, persons, frames, data, categories = batch['id'], batch['videos'], batch['persons'], batch['frames'], batch['coordinates'], batch['categories']\n",
    "\n",
    "    device = 'cuda'\n",
    "\n",
    "    labels = torch.tensor([y[0] for y in categories]).to(device)\n",
    "    # videos = videos.to(device)\n",
    "    # persons = persons.to(device)\n",
    "    frames = frames.to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    outputs = model(data)\n",
    "    \n",
    "    embeddings = torch.cat((embeddings, outputs), 0)\n",
    "    classes = torch.cat((classes, labels), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,100,(500,384))\n",
    "y = torch.randint(0,100,(500,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 384])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.shape)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/s2435462/HRC/code/tsne_silhouette.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000013vscode-remote?line=10'>11</a>\u001b[0m \u001b[39melif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHRC_st\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000013vscode-remote?line=11'>12</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/home/s2435462/HRC/results/tsne_silhouette/HRC_st_tsne_plotting/tsne.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fo:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000013vscode-remote?line=12'>13</a>\u001b[0m         tsne_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(fo)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000013vscode-remote?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhpc-head1.ewi.utwente.nl/home/s2435462/HRC/code/tsne_silhouette.ipynb#ch0000013vscode-remote?line=14'>15</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/home/s2435462/HRC/results/tsne_silhouette/NTU_ttspcc2_833/tsne.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fo:\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# dataset = 'HRC_bpt'\n",
    "dataset = 'HRC_st'\n",
    "# dataset = 'NTU_2D'\n",
    "\n",
    "if dataset == 'HRC_bpt':\n",
    "    with open('/home/s2435462/HRC/results/tsne_silhouette/HRC_ttspcc2_233/tsne.pkl', 'rb') as fo:\n",
    "        tsne_data = pickle.load(fo)\n",
    "elif dataset == 'HRC_st':\n",
    "    with open('/home/s2435462/HRC/results/tsne_silhouette/HRC_st_tsne_plotting/tsne.pkl', 'rb') as fo:\n",
    "        tsne_data = pickle.load(fo)\n",
    "else:\n",
    "    with open('/home/s2435462/HRC/results/tsne_silhouette/NTU_ttspcc2_833/tsne.pkl', 'rb') as fo:\n",
    "        tsne_data = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory import get_categories, get_NTU_categories\n",
    "\n",
    "if dataset == 'HRC_bpt' or dataset == 'HRC_st':\n",
    "    dist = {x : 0 for x in range(len(get_categories()))}\n",
    "    cat = get_categories()\n",
    "else:\n",
    "    dist = {x : 0 for x in range(len(get_NTU_categories()))}\n",
    "    cat = get_NTU_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_embed = {'embeddings' : [],\n",
    "                   'classes' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0}\n",
      "{0: 47939, 1: 79273, 2: 11152, 3: 70182, 4: 50236, 5: 20424, 6: 100543, 7: 27617, 8: 120163, 9: 38374, 10: 101685, 11: 47212, 12: 26287}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x, y = shuffle(tsne_data['embeddings'].tolist(), tsne_data['classes'].tolist())\n",
    "\n",
    "zipped = zip(x, y)\n",
    "\n",
    "print(dist)\n",
    "\n",
    "for embed, class_ in zipped:\n",
    "    dist[class_]+=1\n",
    "    if dist[class_] < 300:\n",
    "        shortened_embed['embeddings'].append(embed)\n",
    "        shortened_embed['classes'].append(class_)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if dataset == 'HRC_bpt':\n",
    "    writer = SummaryWriter('/home/s2435462/HRC/results/tsne_silhouette/HRC_ttspcc2_233/tb')\n",
    "elif dataset == 'HRC_st':\n",
    "    writer = SummaryWriter('/home/s2435462/HRC/results/tsne_silhouette/HRC_st_tsne_plotting/tb')\n",
    "else:\n",
    "    writer = SummaryWriter('/home/s2435462/HRC/results/tsne_silhouette/NTU_ttspcc2_833/tb')\n",
    "\n",
    "writer.add_embedding(np.array(shortened_embed['embeddings']),\n",
    "                    metadata=[cat[i] for i in shortened_embed['classes']])\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1582e50a5ff6820ed038f9dbc2cbb9f235e085337f02244df12954992f636b66"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('copy_of_open-mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
