{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2435462/.conda/envs/copy_of_open-mmlab/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "from torchstat import stat\n",
    "from transformer import TubeletTemporalSpatialPart_concat_chan_2_Transformer, TubeletTemporalPart_concat_chan_1_Transformer, TubeletTemporalTransformer, TubeletTemporalPart_mean_chan_1_Transformer, TubeletTemporalPart_mean_chan_2_Transformer, TubeletTemporalPart_concat_chan_2_Transformer, TemporalTransformer_4, TemporalTransformer_3, TemporalTransformer_2, BodyPartTransformer, SpatialTemporalTransformer, TemporalTransformer, Block, Attention, Mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = '5,2,2'\n",
    "stride = '5,2,2'\n",
    "dataset = 'HRC'\n",
    "embed_dim = 32\n",
    "segment_length = 24\n",
    "num_classes = 120\n",
    "num_joints = 17\n",
    "in_chans = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim 256\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 256\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 32\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 32\n",
      "in_chans 2\n",
      "num_joints 17\n"
     ]
    }
   ],
   "source": [
    "kernel = '5,2,2'\n",
    "stride = '5,2,2'\n",
    "dataset = 'HRC'\n",
    "embed_dim = 256\n",
    "segment_length = 24\n",
    "num_classes = 120\n",
    "num_joints = 17\n",
    "in_chans = 2\n",
    "\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model_1 = TubeletTemporalPart_mean_chan_1_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)\n",
    "\n",
    "\n",
    "# model = TubeletTemporalSpatialPart_concat_chan_2_Transformer(dataset=dataset, embed_dim_ratio=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1, pad_mode = 'constant')\n",
    "model_2 = TubeletTemporalPart_concat_chan_1_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)\n",
    "\n",
    "\n",
    "kernel = '5,3,3'\n",
    "stride = '5,3,3'\n",
    "dataset = 'HRC'\n",
    "embed_dim = 32\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model_3 = TubeletTemporalPart_mean_chan_2_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)\n",
    "\n",
    "model_4 = TubeletTemporalPart_concat_chan_2_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim 32\n",
      "in_chans 2\n",
      "num_joints 17\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "segment_length = 24\n",
    "kernel = '5,2,2'\n",
    "stride = '5,2,2'\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model_2 = TubeletTemporalPart_concat_chan_1_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim_ratio 32\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 544\n"
     ]
    }
   ],
   "source": [
    "sttran2 = SpatialTemporalTransformer(embed_dim_ratio=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim 256\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 32\n",
      "in_chans 2\n",
      "num_joints 17\n"
     ]
    }
   ],
   "source": [
    "kernel = '5,2,2'\n",
    "stride = '5,2,2'\n",
    "dataset = 'HRC'\n",
    "embed_dim = 256\n",
    "segment_length = 24\n",
    "num_classes = 120\n",
    "num_joints = 17\n",
    "in_chans = 2\n",
    "\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model_3 = TubeletTemporalPart_mean_chan_1_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)\n",
    "\n",
    "kernel = '5,3,3'\n",
    "stride = '5,3,3'\n",
    "dataset = 'HRC'\n",
    "embed_dim = 32\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "model_4 = TubeletTemporalPart_mean_chan_2_Transformer(dataset=dataset, embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim 128\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim_ratio 32\n",
      "in_chans 2\n",
      "num_joints 17\n",
      "num_classes 120\n",
      "embed_dim 544\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "segment_length = 12\n",
    "ttran2 = TemporalTransformer_2(embed_dim=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)\n",
    "embed_dim = 32\n",
    "segment_length = 60\n",
    "sttran = SpatialTemporalTransformer(embed_dim_ratio=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 120\n",
      "embed_dim 384\n"
     ]
    }
   ],
   "source": [
    "kernel = '2,3,3'\n",
    "stride = kernel\n",
    "embed_dim = 32\n",
    "segment_length = 24\n",
    "kernel = tuple(map(int, kernel.split(',')))\n",
    "stride = tuple(map(int, stride.split(',')))\n",
    "ttspcc2 = TubeletTemporalSpatialPart_concat_chan_2_Transformer(dataset=dataset, embed_dim_ratio=embed_dim, num_frames=segment_length, num_classes=num_classes, num_joints=num_joints, in_chans=in_chans, kernel=kernel, stride=stride, mlp_ratio=2., qkv_bias=True, qk_scale=None, dropout=0.1, pad_mode = 'constant')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.6718, -5.2553, -4.9711,  ..., -4.9907, -4.6191, -4.9323],\n",
       "        [-5.3369, -5.1256, -5.0853,  ..., -5.3849, -4.6218, -5.0027],\n",
       "        [-5.4009, -5.2142, -5.0759,  ..., -5.7819, -4.8220, -4.2438],\n",
       "        ...,\n",
       "        [-5.9175, -5.3546, -5.3798,  ..., -5.9566, -4.5354, -4.3598],\n",
       "        [-5.4409, -4.9399, -4.8052,  ..., -5.5721, -4.8526, -4.5522],\n",
       "        [-5.5469, -5.3633, -4.9800,  ..., -5.6579, -4.9467, -4.8704]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = torch.randint(1,5,(100, 24, 50)).type(torch.Tensor)\n",
    "model(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv3d: 1-1                            [-1, 256, 4, 3, 3]        5,376\n",
      "├─Conv3d: 1-2                            [-1, 256, 4, 1, 1]        5,376\n",
      "├─Conv3d: 1-3                            [-1, 256, 4, 1, 1]        5,376\n",
      "├─Conv3d: 1-4                            [-1, 256, 4, 1, 1]        5,376\n",
      "├─Conv3d: 1-5                            [-1, 256, 4, 1, 1]        5,376\n",
      "├─Dropout: 1-6                           [-1, 6, 256]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 6, 256]              512\n",
      "|    |    └─Attention: 3-2               [-1, 6, 256]              263,168\n",
      "|    |    └─Dropout: 3-3                 [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 6, 256]              512\n",
      "|    |    └─Mlp: 3-5                     [-1, 6, 256]              262,912\n",
      "|    |    └─Dropout: 3-6                 [-1, 6, 256]              --\n",
      "|    └─Block: 2-2                        [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 6, 256]              512\n",
      "|    |    └─Attention: 3-8               [-1, 6, 256]              263,168\n",
      "|    |    └─Dropout: 3-9                 [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 6, 256]              512\n",
      "|    |    └─Mlp: 3-11                    [-1, 6, 256]              262,912\n",
      "|    |    └─Dropout: 3-12                [-1, 6, 256]              --\n",
      "|    └─Block: 2-3                        [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 6, 256]              512\n",
      "|    |    └─Attention: 3-14              [-1, 6, 256]              263,168\n",
      "|    |    └─Dropout: 3-15                [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 6, 256]              512\n",
      "|    |    └─Mlp: 3-17                    [-1, 6, 256]              262,912\n",
      "|    |    └─Dropout: 3-18                [-1, 6, 256]              --\n",
      "|    └─Block: 2-4                        [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 6, 256]              512\n",
      "|    |    └─Attention: 3-20              [-1, 6, 256]              263,168\n",
      "|    |    └─Dropout: 3-21                [-1, 6, 256]              --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 6, 256]              512\n",
      "|    |    └─Mlp: 3-23                    [-1, 6, 256]              262,912\n",
      "|    |    └─Dropout: 3-24                [-1, 6, 256]              --\n",
      "├─LayerNorm: 1-7                         [-1, 6, 256]              512\n",
      "├─Linear: 1-8                            [-1, 120]                 30,840\n",
      "==========================================================================================\n",
      "Total params: 2,166,648\n",
      "Trainable params: 2,166,648\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.54\n",
      "Params size (MB): 8.27\n",
      "Estimated Total Size (MB): 8.80\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv3d: 1-1                            [-1, 256, 4, 3, 3]        5,376\n",
       "├─Conv3d: 1-2                            [-1, 256, 4, 1, 1]        5,376\n",
       "├─Conv3d: 1-3                            [-1, 256, 4, 1, 1]        5,376\n",
       "├─Conv3d: 1-4                            [-1, 256, 4, 1, 1]        5,376\n",
       "├─Conv3d: 1-5                            [-1, 256, 4, 1, 1]        5,376\n",
       "├─Dropout: 1-6                           [-1, 6, 256]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 6, 256]              512\n",
       "|    |    └─Attention: 3-2               [-1, 6, 256]              263,168\n",
       "|    |    └─Dropout: 3-3                 [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 6, 256]              512\n",
       "|    |    └─Mlp: 3-5                     [-1, 6, 256]              262,912\n",
       "|    |    └─Dropout: 3-6                 [-1, 6, 256]              --\n",
       "|    └─Block: 2-2                        [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 6, 256]              512\n",
       "|    |    └─Attention: 3-8               [-1, 6, 256]              263,168\n",
       "|    |    └─Dropout: 3-9                 [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 6, 256]              512\n",
       "|    |    └─Mlp: 3-11                    [-1, 6, 256]              262,912\n",
       "|    |    └─Dropout: 3-12                [-1, 6, 256]              --\n",
       "|    └─Block: 2-3                        [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 6, 256]              512\n",
       "|    |    └─Attention: 3-14              [-1, 6, 256]              263,168\n",
       "|    |    └─Dropout: 3-15                [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 6, 256]              512\n",
       "|    |    └─Mlp: 3-17                    [-1, 6, 256]              262,912\n",
       "|    |    └─Dropout: 3-18                [-1, 6, 256]              --\n",
       "|    └─Block: 2-4                        [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 6, 256]              512\n",
       "|    |    └─Attention: 3-20              [-1, 6, 256]              263,168\n",
       "|    |    └─Dropout: 3-21                [-1, 6, 256]              --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 6, 256]              512\n",
       "|    |    └─Mlp: 3-23                    [-1, 6, 256]              262,912\n",
       "|    |    └─Dropout: 3-24                [-1, 6, 256]              --\n",
       "├─LayerNorm: 1-7                         [-1, 6, 256]              512\n",
       "├─Linear: 1-8                            [-1, 120]                 30,840\n",
       "==========================================================================================\n",
       "Total params: 2,166,648\n",
       "Trainable params: 2,166,648\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.59\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.54\n",
       "Params size (MB): 8.27\n",
       "Estimated Total Size (MB): 8.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_1, (24, 34)) #BPFormer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 60])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.randn(100, 24,60).shape\n",
    "test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv3d: 1-1                            [-1, 32, 4, 3, 3]         672\n",
      "├─Conv3d: 1-2                            [-1, 32, 4, 3, 3]         672\n",
      "├─Conv3d: 1-3                            [-1, 32, 4, 3, 3]         672\n",
      "├─Conv3d: 1-4                            [-1, 32, 4, 3, 3]         672\n",
      "├─Conv3d: 1-5                            [-1, 32, 4, 3, 3]         672\n",
      "├─Dropout: 1-6                           [-1, 6, 1152]             --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 6, 1152]             2,304\n",
      "|    |    └─Attention: 3-2               [-1, 6, 1152]             5,313,024\n",
      "|    |    └─Dropout: 3-3                 [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 6, 1152]             2,304\n",
      "|    |    └─Mlp: 3-5                     [-1, 6, 1152]             5,311,872\n",
      "|    |    └─Dropout: 3-6                 [-1, 6, 1152]             --\n",
      "|    └─Block: 2-2                        [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 6, 1152]             2,304\n",
      "|    |    └─Attention: 3-8               [-1, 6, 1152]             5,313,024\n",
      "|    |    └─Dropout: 3-9                 [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 6, 1152]             2,304\n",
      "|    |    └─Mlp: 3-11                    [-1, 6, 1152]             5,311,872\n",
      "|    |    └─Dropout: 3-12                [-1, 6, 1152]             --\n",
      "|    └─Block: 2-3                        [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 6, 1152]             2,304\n",
      "|    |    └─Attention: 3-14              [-1, 6, 1152]             5,313,024\n",
      "|    |    └─Dropout: 3-15                [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 6, 1152]             2,304\n",
      "|    |    └─Mlp: 3-17                    [-1, 6, 1152]             5,311,872\n",
      "|    |    └─Dropout: 3-18                [-1, 6, 1152]             --\n",
      "|    └─Block: 2-4                        [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 6, 1152]             2,304\n",
      "|    |    └─Attention: 3-20              [-1, 6, 1152]             5,313,024\n",
      "|    |    └─Dropout: 3-21                [-1, 6, 1152]             --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 6, 1152]             2,304\n",
      "|    |    └─Mlp: 3-23                    [-1, 6, 1152]             5,311,872\n",
      "|    |    └─Dropout: 3-24                [-1, 6, 1152]             --\n",
      "├─LayerNorm: 1-7                         [-1, 6, 1152]             2,304\n",
      "├─Linear: 1-8                            [-1, 120]                 138,360\n",
      "==========================================================================================\n",
      "Total params: 42,662,040\n",
      "Trainable params: 42,662,040\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 127.68\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.00\n",
      "Params size (MB): 162.74\n",
      "Estimated Total Size (MB): 164.74\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv3d: 1-1                            [-1, 32, 4, 3, 3]         672\n",
       "├─Conv3d: 1-2                            [-1, 32, 4, 3, 3]         672\n",
       "├─Conv3d: 1-3                            [-1, 32, 4, 3, 3]         672\n",
       "├─Conv3d: 1-4                            [-1, 32, 4, 3, 3]         672\n",
       "├─Conv3d: 1-5                            [-1, 32, 4, 3, 3]         672\n",
       "├─Dropout: 1-6                           [-1, 6, 1152]             --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 6, 1152]             2,304\n",
       "|    |    └─Attention: 3-2               [-1, 6, 1152]             5,313,024\n",
       "|    |    └─Dropout: 3-3                 [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 6, 1152]             2,304\n",
       "|    |    └─Mlp: 3-5                     [-1, 6, 1152]             5,311,872\n",
       "|    |    └─Dropout: 3-6                 [-1, 6, 1152]             --\n",
       "|    └─Block: 2-2                        [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 6, 1152]             2,304\n",
       "|    |    └─Attention: 3-8               [-1, 6, 1152]             5,313,024\n",
       "|    |    └─Dropout: 3-9                 [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 6, 1152]             2,304\n",
       "|    |    └─Mlp: 3-11                    [-1, 6, 1152]             5,311,872\n",
       "|    |    └─Dropout: 3-12                [-1, 6, 1152]             --\n",
       "|    └─Block: 2-3                        [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 6, 1152]             2,304\n",
       "|    |    └─Attention: 3-14              [-1, 6, 1152]             5,313,024\n",
       "|    |    └─Dropout: 3-15                [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 6, 1152]             2,304\n",
       "|    |    └─Mlp: 3-17                    [-1, 6, 1152]             5,311,872\n",
       "|    |    └─Dropout: 3-18                [-1, 6, 1152]             --\n",
       "|    └─Block: 2-4                        [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 6, 1152]             2,304\n",
       "|    |    └─Attention: 3-20              [-1, 6, 1152]             5,313,024\n",
       "|    |    └─Dropout: 3-21                [-1, 6, 1152]             --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 6, 1152]             2,304\n",
       "|    |    └─Mlp: 3-23                    [-1, 6, 1152]             5,311,872\n",
       "|    |    └─Dropout: 3-24                [-1, 6, 1152]             --\n",
       "├─LayerNorm: 1-7                         [-1, 6, 1152]             2,304\n",
       "├─Linear: 1-8                            [-1, 120]                 138,360\n",
       "==========================================================================================\n",
       "Total params: 42,662,040\n",
       "Trainable params: 42,662,040\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 127.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 2.00\n",
       "Params size (MB): 162.74\n",
       "Estimated Total Size (MB): 164.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, (24, 34)) #BPFormer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv3d: 1-1                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-2                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-3                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-4                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-5                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Dropout: 1-6                           [-1, 6, 32]               --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 6, 32]               64\n",
      "|    |    └─Attention: 3-2               [-1, 6, 32]               4,224\n",
      "|    |    └─Dropout: 3-3                 [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 6, 32]               64\n",
      "|    |    └─Mlp: 3-5                     [-1, 6, 32]               4,192\n",
      "|    |    └─Dropout: 3-6                 [-1, 6, 32]               --\n",
      "|    └─Block: 2-2                        [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 6, 32]               64\n",
      "|    |    └─Attention: 3-8               [-1, 6, 32]               4,224\n",
      "|    |    └─Dropout: 3-9                 [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 6, 32]               64\n",
      "|    |    └─Mlp: 3-11                    [-1, 6, 32]               4,192\n",
      "|    |    └─Dropout: 3-12                [-1, 6, 32]               --\n",
      "|    └─Block: 2-3                        [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 6, 32]               64\n",
      "|    |    └─Attention: 3-14              [-1, 6, 32]               4,224\n",
      "|    |    └─Dropout: 3-15                [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 6, 32]               64\n",
      "|    |    └─Mlp: 3-17                    [-1, 6, 32]               4,192\n",
      "|    |    └─Dropout: 3-18                [-1, 6, 32]               --\n",
      "|    └─Block: 2-4                        [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 6, 32]               64\n",
      "|    |    └─Attention: 3-20              [-1, 6, 32]               4,224\n",
      "|    |    └─Dropout: 3-21                [-1, 6, 32]               --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 6, 32]               64\n",
      "|    |    └─Mlp: 3-23                    [-1, 6, 32]               4,192\n",
      "|    |    └─Dropout: 3-24                [-1, 6, 32]               --\n",
      "├─LayerNorm: 1-7                         [-1, 6, 32]               64\n",
      "├─Linear: 1-8                            [-1, 120]                 3,960\n",
      "==========================================================================================\n",
      "Total params: 52,760\n",
      "Trainable params: 52,760\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.16\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 0.26\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv3d: 1-1                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-2                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-3                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-4                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-5                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Dropout: 1-6                           [-1, 6, 32]               --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 6, 32]               64\n",
       "|    |    └─Attention: 3-2               [-1, 6, 32]               4,224\n",
       "|    |    └─Dropout: 3-3                 [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 6, 32]               64\n",
       "|    |    └─Mlp: 3-5                     [-1, 6, 32]               4,192\n",
       "|    |    └─Dropout: 3-6                 [-1, 6, 32]               --\n",
       "|    └─Block: 2-2                        [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 6, 32]               64\n",
       "|    |    └─Attention: 3-8               [-1, 6, 32]               4,224\n",
       "|    |    └─Dropout: 3-9                 [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 6, 32]               64\n",
       "|    |    └─Mlp: 3-11                    [-1, 6, 32]               4,192\n",
       "|    |    └─Dropout: 3-12                [-1, 6, 32]               --\n",
       "|    └─Block: 2-3                        [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 6, 32]               64\n",
       "|    |    └─Attention: 3-14              [-1, 6, 32]               4,224\n",
       "|    |    └─Dropout: 3-15                [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 6, 32]               64\n",
       "|    |    └─Mlp: 3-17                    [-1, 6, 32]               4,192\n",
       "|    |    └─Dropout: 3-18                [-1, 6, 32]               --\n",
       "|    └─Block: 2-4                        [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 6, 32]               64\n",
       "|    |    └─Attention: 3-20              [-1, 6, 32]               4,224\n",
       "|    |    └─Dropout: 3-21                [-1, 6, 32]               --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 6, 32]               64\n",
       "|    |    └─Mlp: 3-23                    [-1, 6, 32]               4,192\n",
       "|    |    └─Dropout: 3-24                [-1, 6, 32]               --\n",
       "├─LayerNorm: 1-7                         [-1, 6, 32]               64\n",
       "├─Linear: 1-8                            [-1, 120]                 3,960\n",
       "==========================================================================================\n",
       "Total params: 52,760\n",
       "Trainable params: 52,760\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.16\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 0.20\n",
       "Estimated Total Size (MB): 0.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_3, (24,34)) #BPFormer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv3d: 1-1                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-2                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-3                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-4                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Conv3d: 1-5                            [-1, 32, 4, 1, 1]         2,912\n",
      "├─Dropout: 1-6                           [-1, 6, 128]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 6, 128]              256\n",
      "|    |    └─Attention: 3-2               [-1, 6, 128]              66,048\n",
      "|    |    └─Dropout: 3-3                 [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 6, 128]              256\n",
      "|    |    └─Mlp: 3-5                     [-1, 6, 128]              65,920\n",
      "|    |    └─Dropout: 3-6                 [-1, 6, 128]              --\n",
      "|    └─Block: 2-2                        [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 6, 128]              256\n",
      "|    |    └─Attention: 3-8               [-1, 6, 128]              66,048\n",
      "|    |    └─Dropout: 3-9                 [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 6, 128]              256\n",
      "|    |    └─Mlp: 3-11                    [-1, 6, 128]              65,920\n",
      "|    |    └─Dropout: 3-12                [-1, 6, 128]              --\n",
      "|    └─Block: 2-3                        [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 6, 128]              256\n",
      "|    |    └─Attention: 3-14              [-1, 6, 128]              66,048\n",
      "|    |    └─Dropout: 3-15                [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 6, 128]              256\n",
      "|    |    └─Mlp: 3-17                    [-1, 6, 128]              65,920\n",
      "|    |    └─Dropout: 3-18                [-1, 6, 128]              --\n",
      "|    └─Block: 2-4                        [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 6, 128]              256\n",
      "|    |    └─Attention: 3-20              [-1, 6, 128]              66,048\n",
      "|    |    └─Dropout: 3-21                [-1, 6, 128]              --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 6, 128]              256\n",
      "|    |    └─Mlp: 3-23                    [-1, 6, 128]              65,920\n",
      "|    |    └─Dropout: 3-24                [-1, 6, 128]              --\n",
      "├─LayerNorm: 1-7                         [-1, 6, 128]              256\n",
      "├─Linear: 1-8                            [-1, 120]                 15,480\n",
      "==========================================================================================\n",
      "Total params: 560,216\n",
      "Trainable params: 560,216\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.65\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 2.14\n",
      "Estimated Total Size (MB): 2.36\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv3d: 1-1                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-2                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-3                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-4                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Conv3d: 1-5                            [-1, 32, 4, 1, 1]         2,912\n",
       "├─Dropout: 1-6                           [-1, 6, 128]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 6, 128]              256\n",
       "|    |    └─Attention: 3-2               [-1, 6, 128]              66,048\n",
       "|    |    └─Dropout: 3-3                 [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 6, 128]              256\n",
       "|    |    └─Mlp: 3-5                     [-1, 6, 128]              65,920\n",
       "|    |    └─Dropout: 3-6                 [-1, 6, 128]              --\n",
       "|    └─Block: 2-2                        [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 6, 128]              256\n",
       "|    |    └─Attention: 3-8               [-1, 6, 128]              66,048\n",
       "|    |    └─Dropout: 3-9                 [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 6, 128]              256\n",
       "|    |    └─Mlp: 3-11                    [-1, 6, 128]              65,920\n",
       "|    |    └─Dropout: 3-12                [-1, 6, 128]              --\n",
       "|    └─Block: 2-3                        [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 6, 128]              256\n",
       "|    |    └─Attention: 3-14              [-1, 6, 128]              66,048\n",
       "|    |    └─Dropout: 3-15                [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 6, 128]              256\n",
       "|    |    └─Mlp: 3-17                    [-1, 6, 128]              65,920\n",
       "|    |    └─Dropout: 3-18                [-1, 6, 128]              --\n",
       "|    └─Block: 2-4                        [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 6, 128]              256\n",
       "|    |    └─Attention: 3-20              [-1, 6, 128]              66,048\n",
       "|    |    └─Dropout: 3-21                [-1, 6, 128]              --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 6, 128]              256\n",
       "|    |    └─Mlp: 3-23                    [-1, 6, 128]              65,920\n",
       "|    |    └─Dropout: 3-24                [-1, 6, 128]              --\n",
       "├─LayerNorm: 1-7                         [-1, 6, 128]              256\n",
       "├─Linear: 1-8                            [-1, 120]                 15,480\n",
       "==========================================================================================\n",
       "Total params: 560,216\n",
       "Trainable params: 560,216\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.65\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.22\n",
       "Params size (MB): 2.14\n",
       "Estimated Total Size (MB): 2.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_4, (24,34)) #BPFormer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 34, 128]             1,664\n",
      "├─Dropout: 1-2                           [-1, 35, 128]             --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 35, 128]             256\n",
      "|    |    └─Attention: 3-2               [-1, 35, 128]             66,048\n",
      "|    |    └─Dropout: 3-3                 [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 35, 128]             256\n",
      "|    |    └─Mlp: 3-5                     [-1, 35, 128]             65,920\n",
      "|    |    └─Dropout: 3-6                 [-1, 35, 128]             --\n",
      "|    └─Block: 2-2                        [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 35, 128]             256\n",
      "|    |    └─Attention: 3-8               [-1, 35, 128]             66,048\n",
      "|    |    └─Dropout: 3-9                 [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 35, 128]             256\n",
      "|    |    └─Mlp: 3-11                    [-1, 35, 128]             65,920\n",
      "|    |    └─Dropout: 3-12                [-1, 35, 128]             --\n",
      "|    └─Block: 2-3                        [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 35, 128]             256\n",
      "|    |    └─Attention: 3-14              [-1, 35, 128]             66,048\n",
      "|    |    └─Dropout: 3-15                [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 35, 128]             256\n",
      "|    |    └─Mlp: 3-17                    [-1, 35, 128]             65,920\n",
      "|    |    └─Dropout: 3-18                [-1, 35, 128]             --\n",
      "|    └─Block: 2-4                        [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 35, 128]             256\n",
      "|    |    └─Attention: 3-20              [-1, 35, 128]             66,048\n",
      "|    |    └─Dropout: 3-21                [-1, 35, 128]             --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 35, 128]             256\n",
      "|    |    └─Mlp: 3-23                    [-1, 35, 128]             65,920\n",
      "|    |    └─Dropout: 3-24                [-1, 35, 128]             --\n",
      "├─LayerNorm: 1-3                         [-1, 35, 128]             256\n",
      "├─Linear: 1-4                            [-1, 120]                 15,480\n",
      "==========================================================================================\n",
      "Total params: 547,320\n",
      "Trainable params: 547,320\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.30\n",
      "Params size (MB): 2.09\n",
      "Estimated Total Size (MB): 3.39\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 34, 128]             1,664\n",
       "├─Dropout: 1-2                           [-1, 35, 128]             --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 35, 128]             256\n",
       "|    |    └─Attention: 3-2               [-1, 35, 128]             66,048\n",
       "|    |    └─Dropout: 3-3                 [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 35, 128]             256\n",
       "|    |    └─Mlp: 3-5                     [-1, 35, 128]             65,920\n",
       "|    |    └─Dropout: 3-6                 [-1, 35, 128]             --\n",
       "|    └─Block: 2-2                        [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 35, 128]             256\n",
       "|    |    └─Attention: 3-8               [-1, 35, 128]             66,048\n",
       "|    |    └─Dropout: 3-9                 [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 35, 128]             256\n",
       "|    |    └─Mlp: 3-11                    [-1, 35, 128]             65,920\n",
       "|    |    └─Dropout: 3-12                [-1, 35, 128]             --\n",
       "|    └─Block: 2-3                        [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 35, 128]             256\n",
       "|    |    └─Attention: 3-14              [-1, 35, 128]             66,048\n",
       "|    |    └─Dropout: 3-15                [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 35, 128]             256\n",
       "|    |    └─Mlp: 3-17                    [-1, 35, 128]             65,920\n",
       "|    |    └─Dropout: 3-18                [-1, 35, 128]             --\n",
       "|    └─Block: 2-4                        [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 35, 128]             256\n",
       "|    |    └─Attention: 3-20              [-1, 35, 128]             66,048\n",
       "|    |    └─Dropout: 3-21                [-1, 35, 128]             --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 35, 128]             256\n",
       "|    |    └─Mlp: 3-23                    [-1, 35, 128]             65,920\n",
       "|    |    └─Dropout: 3-24                [-1, 35, 128]             --\n",
       "├─LayerNorm: 1-3                         [-1, 35, 128]             256\n",
       "├─Linear: 1-4                            [-1, 120]                 15,480\n",
       "==========================================================================================\n",
       "Total params: 547,320\n",
       "Trainable params: 547,320\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.59\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.30\n",
       "Params size (MB): 2.09\n",
       "Estimated Total Size (MB): 3.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ttran2, (12, 34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 17, 32]              96\n",
      "├─Dropout: 1-2                           [-1, 17, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 17, 32]              64\n",
      "|    |    └─Attention: 3-2               [-1, 17, 32]              4,224\n",
      "|    |    └─Dropout: 3-3                 [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 17, 32]              64\n",
      "|    |    └─Mlp: 3-5                     [-1, 17, 32]              4,192\n",
      "|    |    └─Dropout: 3-6                 [-1, 17, 32]              --\n",
      "|    └─Block: 2-2                        [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 17, 32]              64\n",
      "|    |    └─Attention: 3-8               [-1, 17, 32]              4,224\n",
      "|    |    └─Dropout: 3-9                 [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 17, 32]              64\n",
      "|    |    └─Mlp: 3-11                    [-1, 17, 32]              4,192\n",
      "|    |    └─Dropout: 3-12                [-1, 17, 32]              --\n",
      "|    └─Block: 2-3                        [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 17, 32]              64\n",
      "|    |    └─Attention: 3-14              [-1, 17, 32]              4,224\n",
      "|    |    └─Dropout: 3-15                [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 17, 32]              64\n",
      "|    |    └─Mlp: 3-17                    [-1, 17, 32]              4,192\n",
      "|    |    └─Dropout: 3-18                [-1, 17, 32]              --\n",
      "|    └─Block: 2-4                        [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 17, 32]              64\n",
      "|    |    └─Attention: 3-20              [-1, 17, 32]              4,224\n",
      "|    |    └─Dropout: 3-21                [-1, 17, 32]              --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 17, 32]              64\n",
      "|    |    └─Mlp: 3-23                    [-1, 17, 32]              4,192\n",
      "|    |    └─Dropout: 3-24                [-1, 17, 32]              --\n",
      "├─LayerNorm: 1-3                         [-1, 17, 32]              64\n",
      "├─Dropout: 1-4                           [-1, 61, 544]             --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-5                        [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-25              [-1, 61, 544]             1,088\n",
      "|    |    └─Attention: 3-26              [-1, 61, 544]             1,185,920\n",
      "|    |    └─Dropout: 3-27                [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-28              [-1, 61, 544]             1,088\n",
      "|    |    └─Mlp: 3-29                    [-1, 61, 544]             1,185,376\n",
      "|    |    └─Dropout: 3-30                [-1, 61, 544]             --\n",
      "|    └─Block: 2-6                        [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-31              [-1, 61, 544]             1,088\n",
      "|    |    └─Attention: 3-32              [-1, 61, 544]             1,185,920\n",
      "|    |    └─Dropout: 3-33                [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-34              [-1, 61, 544]             1,088\n",
      "|    |    └─Mlp: 3-35                    [-1, 61, 544]             1,185,376\n",
      "|    |    └─Dropout: 3-36                [-1, 61, 544]             --\n",
      "|    └─Block: 2-7                        [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-37              [-1, 61, 544]             1,088\n",
      "|    |    └─Attention: 3-38              [-1, 61, 544]             1,185,920\n",
      "|    |    └─Dropout: 3-39                [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-40              [-1, 61, 544]             1,088\n",
      "|    |    └─Mlp: 3-41                    [-1, 61, 544]             1,185,376\n",
      "|    |    └─Dropout: 3-42                [-1, 61, 544]             --\n",
      "|    └─Block: 2-8                        [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-43              [-1, 61, 544]             1,088\n",
      "|    |    └─Attention: 3-44              [-1, 61, 544]             1,185,920\n",
      "|    |    └─Dropout: 3-45                [-1, 61, 544]             --\n",
      "|    |    └─LayerNorm: 3-46              [-1, 61, 544]             1,088\n",
      "|    |    └─Mlp: 3-47                    [-1, 61, 544]             1,185,376\n",
      "|    |    └─Dropout: 3-48                [-1, 61, 544]             --\n",
      "├─LayerNorm: 1-5                         [-1, 61, 544]             1,088\n",
      "├─Linear: 1-6                            [-1, 120]                 65,400\n",
      "==========================================================================================\n",
      "Total params: 9,594,712\n",
      "Trainable params: 9,594,712\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 28.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.53\n",
      "Params size (MB): 36.60\n",
      "Estimated Total Size (MB): 46.13\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 17, 32]              96\n",
       "├─Dropout: 1-2                           [-1, 17, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 17, 32]              64\n",
       "|    |    └─Attention: 3-2               [-1, 17, 32]              4,224\n",
       "|    |    └─Dropout: 3-3                 [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 17, 32]              64\n",
       "|    |    └─Mlp: 3-5                     [-1, 17, 32]              4,192\n",
       "|    |    └─Dropout: 3-6                 [-1, 17, 32]              --\n",
       "|    └─Block: 2-2                        [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 17, 32]              64\n",
       "|    |    └─Attention: 3-8               [-1, 17, 32]              4,224\n",
       "|    |    └─Dropout: 3-9                 [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 17, 32]              64\n",
       "|    |    └─Mlp: 3-11                    [-1, 17, 32]              4,192\n",
       "|    |    └─Dropout: 3-12                [-1, 17, 32]              --\n",
       "|    └─Block: 2-3                        [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 17, 32]              64\n",
       "|    |    └─Attention: 3-14              [-1, 17, 32]              4,224\n",
       "|    |    └─Dropout: 3-15                [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 17, 32]              64\n",
       "|    |    └─Mlp: 3-17                    [-1, 17, 32]              4,192\n",
       "|    |    └─Dropout: 3-18                [-1, 17, 32]              --\n",
       "|    └─Block: 2-4                        [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 17, 32]              64\n",
       "|    |    └─Attention: 3-20              [-1, 17, 32]              4,224\n",
       "|    |    └─Dropout: 3-21                [-1, 17, 32]              --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 17, 32]              64\n",
       "|    |    └─Mlp: 3-23                    [-1, 17, 32]              4,192\n",
       "|    |    └─Dropout: 3-24                [-1, 17, 32]              --\n",
       "├─LayerNorm: 1-3                         [-1, 17, 32]              64\n",
       "├─Dropout: 1-4                           [-1, 61, 544]             --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-5                        [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-25              [-1, 61, 544]             1,088\n",
       "|    |    └─Attention: 3-26              [-1, 61, 544]             1,185,920\n",
       "|    |    └─Dropout: 3-27                [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-28              [-1, 61, 544]             1,088\n",
       "|    |    └─Mlp: 3-29                    [-1, 61, 544]             1,185,376\n",
       "|    |    └─Dropout: 3-30                [-1, 61, 544]             --\n",
       "|    └─Block: 2-6                        [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-31              [-1, 61, 544]             1,088\n",
       "|    |    └─Attention: 3-32              [-1, 61, 544]             1,185,920\n",
       "|    |    └─Dropout: 3-33                [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-34              [-1, 61, 544]             1,088\n",
       "|    |    └─Mlp: 3-35                    [-1, 61, 544]             1,185,376\n",
       "|    |    └─Dropout: 3-36                [-1, 61, 544]             --\n",
       "|    └─Block: 2-7                        [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-37              [-1, 61, 544]             1,088\n",
       "|    |    └─Attention: 3-38              [-1, 61, 544]             1,185,920\n",
       "|    |    └─Dropout: 3-39                [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-40              [-1, 61, 544]             1,088\n",
       "|    |    └─Mlp: 3-41                    [-1, 61, 544]             1,185,376\n",
       "|    |    └─Dropout: 3-42                [-1, 61, 544]             --\n",
       "|    └─Block: 2-8                        [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-43              [-1, 61, 544]             1,088\n",
       "|    |    └─Attention: 3-44              [-1, 61, 544]             1,185,920\n",
       "|    |    └─Dropout: 3-45                [-1, 61, 544]             --\n",
       "|    |    └─LayerNorm: 3-46              [-1, 61, 544]             1,088\n",
       "|    |    └─Mlp: 3-47                    [-1, 61, 544]             1,185,376\n",
       "|    |    └─Dropout: 3-48                [-1, 61, 544]             --\n",
       "├─LayerNorm: 1-5                         [-1, 61, 544]             1,088\n",
       "├─Linear: 1-6                            [-1, 120]                 65,400\n",
       "==========================================================================================\n",
       "Total params: 9,594,712\n",
       "Trainable params: 9,594,712\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 28.58\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 9.53\n",
       "Params size (MB): 36.60\n",
       "Estimated Total Size (MB): 46.13\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(sttran, (60, 34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv3d: 1-1                            [-1, 32, 12, 1, 1]        1,184\n",
      "├─Dropout: 1-2                           [-1, 12, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-1                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-2               [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-3                 [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-4               [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-5                     [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-6                 [-1, 12, 32]              --\n",
      "|    └─Block: 2-2                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-7               [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-8               [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-9                 [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-10              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-11                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-12                [-1, 12, 32]              --\n",
      "|    └─Block: 2-3                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-14              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-15                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-16              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-17                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-18                [-1, 12, 32]              --\n",
      "|    └─Block: 2-4                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-19              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-20              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-21                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-22              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-23                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-24                [-1, 12, 32]              --\n",
      "├─LayerNorm: 1-3                         [-1, 12, 32]              64\n",
      "├─Conv3d: 1-4                            [-1, 32, 12, 1, 1]        1,184\n",
      "├─Dropout: 1-5                           [-1, 12, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-5                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-25              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-26              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-27                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-28              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-29                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-30                [-1, 12, 32]              --\n",
      "|    └─Block: 2-6                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-31              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-32              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-33                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-34              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-35                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-36                [-1, 12, 32]              --\n",
      "|    └─Block: 2-7                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-37              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-38              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-39                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-40              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-41                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-42                [-1, 12, 32]              --\n",
      "|    └─Block: 2-8                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-43              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-44              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-45                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-46              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-47                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-48                [-1, 12, 32]              --\n",
      "├─LayerNorm: 1-6                         [-1, 12, 32]              (recursive)\n",
      "├─Conv3d: 1-7                            [-1, 32, 12, 1, 1]        1,184\n",
      "├─Dropout: 1-8                           [-1, 12, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-9                        [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-49              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-50              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-51                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-52              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-53                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-54                [-1, 12, 32]              --\n",
      "|    └─Block: 2-10                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-55              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-56              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-57                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-58              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-59                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-60                [-1, 12, 32]              --\n",
      "|    └─Block: 2-11                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-61              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-62              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-63                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-64              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-65                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-66                [-1, 12, 32]              --\n",
      "|    └─Block: 2-12                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-67              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-68              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-69                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-70              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-71                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-72                [-1, 12, 32]              --\n",
      "├─LayerNorm: 1-9                         [-1, 12, 32]              (recursive)\n",
      "├─Conv3d: 1-10                           [-1, 32, 12, 1, 1]        1,184\n",
      "├─Dropout: 1-11                          [-1, 12, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-13                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-73              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-74              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-75                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-76              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-77                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-78                [-1, 12, 32]              --\n",
      "|    └─Block: 2-14                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-79              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-80              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-81                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-82              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-83                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-84                [-1, 12, 32]              --\n",
      "|    └─Block: 2-15                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-85              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-86              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-87                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-88              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-89                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-90                [-1, 12, 32]              --\n",
      "|    └─Block: 2-16                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-91              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-92              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-93                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-94              [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-95                    [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-96                [-1, 12, 32]              --\n",
      "├─LayerNorm: 1-12                        [-1, 12, 32]              (recursive)\n",
      "├─Conv3d: 1-13                           [-1, 32, 12, 1, 1]        1,184\n",
      "├─Dropout: 1-14                          [-1, 12, 32]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-17                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-97              [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-98              [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-99                [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-100             [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-101                   [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-102               [-1, 12, 32]              --\n",
      "|    └─Block: 2-18                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-103             [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-104             [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-105               [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-106             [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-107                   [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-108               [-1, 12, 32]              --\n",
      "|    └─Block: 2-19                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-109             [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-110             [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-111               [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-112             [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-113                   [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-114               [-1, 12, 32]              --\n",
      "|    └─Block: 2-20                       [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-115             [-1, 12, 32]              64\n",
      "|    |    └─Attention: 3-116             [-1, 12, 32]              4,224\n",
      "|    |    └─Dropout: 3-117               [-1, 12, 32]              --\n",
      "|    |    └─LayerNorm: 3-118             [-1, 12, 32]              64\n",
      "|    |    └─Mlp: 3-119                   [-1, 12, 32]              4,192\n",
      "|    |    └─Dropout: 3-120               [-1, 12, 32]              --\n",
      "├─LayerNorm: 1-15                        [-1, 12, 32]              (recursive)\n",
      "├─Dropout: 1-16                          [-1, 6, 384]              --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Block: 2-21                       [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-121             [-1, 6, 384]              768\n",
      "|    |    └─Attention: 3-122             [-1, 6, 384]              591,360\n",
      "|    |    └─Dropout: 3-123               [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-124             [-1, 6, 384]              768\n",
      "|    |    └─Mlp: 3-125                   [-1, 6, 384]              590,976\n",
      "|    |    └─Dropout: 3-126               [-1, 6, 384]              --\n",
      "|    └─Block: 2-22                       [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-127             [-1, 6, 384]              768\n",
      "|    |    └─Attention: 3-128             [-1, 6, 384]              591,360\n",
      "|    |    └─Dropout: 3-129               [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-130             [-1, 6, 384]              768\n",
      "|    |    └─Mlp: 3-131                   [-1, 6, 384]              590,976\n",
      "|    |    └─Dropout: 3-132               [-1, 6, 384]              --\n",
      "|    └─Block: 2-23                       [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-133             [-1, 6, 384]              768\n",
      "|    |    └─Attention: 3-134             [-1, 6, 384]              591,360\n",
      "|    |    └─Dropout: 3-135               [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-136             [-1, 6, 384]              768\n",
      "|    |    └─Mlp: 3-137                   [-1, 6, 384]              590,976\n",
      "|    |    └─Dropout: 3-138               [-1, 6, 384]              --\n",
      "|    └─Block: 2-24                       [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-139             [-1, 6, 384]              768\n",
      "|    |    └─Attention: 3-140             [-1, 6, 384]              591,360\n",
      "|    |    └─Dropout: 3-141               [-1, 6, 384]              --\n",
      "|    |    └─LayerNorm: 3-142             [-1, 6, 384]              768\n",
      "|    |    └─Mlp: 3-143                   [-1, 6, 384]              590,976\n",
      "|    |    └─Dropout: 3-144               [-1, 6, 384]              --\n",
      "├─LayerNorm: 1-17                        [-1, 6, 384]              768\n",
      "├─Linear: 1-18                           [-1, 120]                 46,200\n",
      "==========================================================================================\n",
      "Total params: 4,959,320\n",
      "Trainable params: 4,959,320\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.77\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.20\n",
      "Params size (MB): 18.92\n",
      "Estimated Total Size (MB): 20.12\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv3d: 1-1                            [-1, 32, 12, 1, 1]        1,184\n",
       "├─Dropout: 1-2                           [-1, 12, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-1                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-1               [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-2               [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-3                 [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-4               [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-5                     [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-6                 [-1, 12, 32]              --\n",
       "|    └─Block: 2-2                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-7               [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-8               [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-9                 [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-10              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-11                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-12                [-1, 12, 32]              --\n",
       "|    └─Block: 2-3                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-13              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-14              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-15                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-16              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-17                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-18                [-1, 12, 32]              --\n",
       "|    └─Block: 2-4                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-19              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-20              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-21                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-22              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-23                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-24                [-1, 12, 32]              --\n",
       "├─LayerNorm: 1-3                         [-1, 12, 32]              64\n",
       "├─Conv3d: 1-4                            [-1, 32, 12, 1, 1]        1,184\n",
       "├─Dropout: 1-5                           [-1, 12, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-5                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-25              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-26              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-27                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-28              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-29                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-30                [-1, 12, 32]              --\n",
       "|    └─Block: 2-6                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-31              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-32              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-33                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-34              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-35                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-36                [-1, 12, 32]              --\n",
       "|    └─Block: 2-7                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-37              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-38              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-39                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-40              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-41                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-42                [-1, 12, 32]              --\n",
       "|    └─Block: 2-8                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-43              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-44              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-45                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-46              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-47                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-48                [-1, 12, 32]              --\n",
       "├─LayerNorm: 1-6                         [-1, 12, 32]              (recursive)\n",
       "├─Conv3d: 1-7                            [-1, 32, 12, 1, 1]        1,184\n",
       "├─Dropout: 1-8                           [-1, 12, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-9                        [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-49              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-50              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-51                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-52              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-53                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-54                [-1, 12, 32]              --\n",
       "|    └─Block: 2-10                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-55              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-56              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-57                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-58              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-59                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-60                [-1, 12, 32]              --\n",
       "|    └─Block: 2-11                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-61              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-62              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-63                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-64              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-65                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-66                [-1, 12, 32]              --\n",
       "|    └─Block: 2-12                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-67              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-68              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-69                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-70              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-71                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-72                [-1, 12, 32]              --\n",
       "├─LayerNorm: 1-9                         [-1, 12, 32]              (recursive)\n",
       "├─Conv3d: 1-10                           [-1, 32, 12, 1, 1]        1,184\n",
       "├─Dropout: 1-11                          [-1, 12, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-13                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-73              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-74              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-75                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-76              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-77                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-78                [-1, 12, 32]              --\n",
       "|    └─Block: 2-14                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-79              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-80              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-81                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-82              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-83                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-84                [-1, 12, 32]              --\n",
       "|    └─Block: 2-15                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-85              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-86              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-87                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-88              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-89                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-90                [-1, 12, 32]              --\n",
       "|    └─Block: 2-16                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-91              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-92              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-93                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-94              [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-95                    [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-96                [-1, 12, 32]              --\n",
       "├─LayerNorm: 1-12                        [-1, 12, 32]              (recursive)\n",
       "├─Conv3d: 1-13                           [-1, 32, 12, 1, 1]        1,184\n",
       "├─Dropout: 1-14                          [-1, 12, 32]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-17                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-97              [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-98              [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-99                [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-100             [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-101                   [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-102               [-1, 12, 32]              --\n",
       "|    └─Block: 2-18                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-103             [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-104             [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-105               [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-106             [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-107                   [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-108               [-1, 12, 32]              --\n",
       "|    └─Block: 2-19                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-109             [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-110             [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-111               [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-112             [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-113                   [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-114               [-1, 12, 32]              --\n",
       "|    └─Block: 2-20                       [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-115             [-1, 12, 32]              64\n",
       "|    |    └─Attention: 3-116             [-1, 12, 32]              4,224\n",
       "|    |    └─Dropout: 3-117               [-1, 12, 32]              --\n",
       "|    |    └─LayerNorm: 3-118             [-1, 12, 32]              64\n",
       "|    |    └─Mlp: 3-119                   [-1, 12, 32]              4,192\n",
       "|    |    └─Dropout: 3-120               [-1, 12, 32]              --\n",
       "├─LayerNorm: 1-15                        [-1, 12, 32]              (recursive)\n",
       "├─Dropout: 1-16                          [-1, 6, 384]              --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Block: 2-21                       [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-121             [-1, 6, 384]              768\n",
       "|    |    └─Attention: 3-122             [-1, 6, 384]              591,360\n",
       "|    |    └─Dropout: 3-123               [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-124             [-1, 6, 384]              768\n",
       "|    |    └─Mlp: 3-125                   [-1, 6, 384]              590,976\n",
       "|    |    └─Dropout: 3-126               [-1, 6, 384]              --\n",
       "|    └─Block: 2-22                       [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-127             [-1, 6, 384]              768\n",
       "|    |    └─Attention: 3-128             [-1, 6, 384]              591,360\n",
       "|    |    └─Dropout: 3-129               [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-130             [-1, 6, 384]              768\n",
       "|    |    └─Mlp: 3-131                   [-1, 6, 384]              590,976\n",
       "|    |    └─Dropout: 3-132               [-1, 6, 384]              --\n",
       "|    └─Block: 2-23                       [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-133             [-1, 6, 384]              768\n",
       "|    |    └─Attention: 3-134             [-1, 6, 384]              591,360\n",
       "|    |    └─Dropout: 3-135               [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-136             [-1, 6, 384]              768\n",
       "|    |    └─Mlp: 3-137                   [-1, 6, 384]              590,976\n",
       "|    |    └─Dropout: 3-138               [-1, 6, 384]              --\n",
       "|    └─Block: 2-24                       [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-139             [-1, 6, 384]              768\n",
       "|    |    └─Attention: 3-140             [-1, 6, 384]              591,360\n",
       "|    |    └─Dropout: 3-141               [-1, 6, 384]              --\n",
       "|    |    └─LayerNorm: 3-142             [-1, 6, 384]              768\n",
       "|    |    └─Mlp: 3-143                   [-1, 6, 384]              590,976\n",
       "|    |    └─Dropout: 3-144               [-1, 6, 384]              --\n",
       "├─LayerNorm: 1-17                        [-1, 6, 384]              768\n",
       "├─Linear: 1-18                           [-1, 120]                 46,200\n",
       "==========================================================================================\n",
       "Total params: 4,959,320\n",
       "Trainable params: 4,959,320\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 14.77\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.20\n",
       "Params size (MB): 18.92\n",
       "Estimated Total Size (MB): 20.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ttspcc2, (24, 34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "2341248.0 492312.0\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 24, 34)\n",
    "\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "502338304.0 9594712.0\n"
     ]
    }
   ],
   "source": [
    "macs, params = profile(model_2, inputs=(input, ))\n",
    "print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['ST-Tran', 'BPTubeFormer-2', 'T-Tran-2', 'BPTubeFormer-2']\n",
    "men_means = [53.5, 30.5, 18.6, 3.9]\n",
    "women_means = [9.5, 4.9, 0.53, 0.7]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.20  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='MACS (x10\\u2079)')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='No. of  Parameters')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x, labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "# plt.figure(figsize=(10,30))\n",
    "\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(6)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1582e50a5ff6820ed038f9dbc2cbb9f235e085337f02244df12954992f636b66"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('copy_of_open-mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
